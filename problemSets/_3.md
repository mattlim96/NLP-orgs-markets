# Using ‘doc2vec’ to mapping documents onto the vector space

**Context**

Consider the [ai_in_finance.json](https://github.com/simoneSantoni/NLP-orgs-markets/blob/master/sampleData/econNewspaper/ai_in_finance.json) file, containing 4K+ articles dealing with the topics of AI & financial services from The Wall Street Journal and The Financial Times. For a description of the corpus, see [Lanzolla, Gianvito, Simone Santoni, and Christopher Tucci. "Unlocking value from AI in financial services: strategic and organizational tradeoffs vs. media narratives." In Artificial Intelligence for Sustainable Value Creation. Edward Elgar Publishing, 2021.](https://github.com/simoneSantoni/NLP-orgs-markets/blob/46dad729070a5125c95adc214abbec312cae7077/sampleData/econNewspaper/lanzolla_santoni_tucci.pdf)

**Problem**

Use the doc2vec — as per [Training a doc2vec embedding with Gensim](https://www.notion.so/Training-a-doc2vec-embedding-with-Gensim-f4df0ca2bb9d4d11b842d67f4bd0b7e1) — to:

- get document-level representations for the 4K+ articles in the corpus
- visualize the position of the individual documents in the vector space (equivalently to [Mapping documents onto the vector space](https://www.notion.so/Mapping-documents-onto-the-vector-space-c6bbfb18c6a0443ab3525005d4a3c250))

Then, compare and contrast the results achieved the doc2vec algorithm against the results achieved with the BoW or TFIDF approach — see [Mapping documents onto the vector space](https://www.notion.so/Mapping-documents-onto-the-vector-space-c6bbfb18c6a0443ab3525005d4a3c250). Can you spot any pairs of documents that are similar for the doc2vec approach and not so similar (or not similar at all) in terms of the Bow or TFIDF representations?